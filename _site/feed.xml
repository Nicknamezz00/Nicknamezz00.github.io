<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aaron&apos;s Blog</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 24 Jul 2023 11:32:25 +0800</pubDate>
    <lastBuildDate>Mon, 24 Jul 2023 11:32:25 +0800</lastBuildDate>
    <generator>Jekyll v4.3.2</generator>
    
      <item>
        <title>Interview</title>
        <description>&lt;h2 id=&quot;面经&quot;&gt;面经&lt;/h2&gt;

&lt;h3 id=&quot;操作系统&quot;&gt;操作系统&lt;/h3&gt;

&lt;p&gt;：操作系统中内核态和用户态的区别？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;操作系统需要两种CPU状态：内核态、用户态&lt;/li&gt;
  &lt;li&gt;转换
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;用户态—&amp;gt;内核态：&lt;/strong&gt;唯一途径是通过中断、异常、陷入机制（访管指令）&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;内核态—&amp;gt;用户态：&lt;/strong&gt;设置程序状态字PSW&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;区别
    &lt;ul&gt;
      &lt;li&gt;处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的&lt;/li&gt;
      &lt;li&gt;处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;通常来说，以下三种情况会导致用户态到内核态的切换
    &lt;ul&gt;
      &lt;li&gt;系统调用&lt;/li&gt;
      &lt;li&gt;异常&lt;/li&gt;
      &lt;li&gt;外围设备的中断&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;：敲键盘发生的中断？&lt;/p&gt;

&lt;p&gt;键盘通过USB连接到电脑上电后，键盘内部会有一个芯片以轮询的方式接收电信号，当有按下/弹起事件发生时，该芯片会捕获到这个电信号，并将该信号封装成一个包含键位组合（Ctrl+C）、动作（按下）的消息并放到缓存中&lt;/p&gt;

&lt;p&gt;接下来将一个中断信号通过USB接口发送出去，这个信号会沿着IO总线来到主板的南桥，南桥负责一些外设与CPU之间的沟通，南桥内部包含有一些硬件控制器和中断控制，硬件控制器中就包含USB控制器，USB控制器在捕获到该中断信号后会通知中断控制器，中断控制器会向CPU的某个核心发送中断请求；&lt;/p&gt;

&lt;p&gt;核心在收到中断请求后会将当前线程的上下文保存到内核栈中，之后便开始处理该中断，该核心会从IDTR寄存器中取出中断向量表的地址，该核心从中断向量表中取出刚才的中断信号对应的处理函数的地址，下一个周期开始执行该处理函数。&lt;/p&gt;

&lt;p&gt;该处理函数在是预先写好在内存中的，处理函数会通知驱动程序，将之前存放在缓存中的消息取出并进行转码，应用程序通过读取消息队列就可以读取到我们按下的字符并将其存放至该线程的某个逻辑地址内，对应内存中的某个物理地址。&lt;/p&gt;

&lt;p&gt;之后若想把该字符显示在屏幕上，那就需要由应用程序再一次触发中断，CPU某个核心收到该中断请求后会通过查询中断向量表的方式获得一个处理函数的地址，该处理函数会通知屏幕驱动程序同时将要显示的内容发送给屏幕驱动程序，之后屏幕驱动程序通知屏幕设备控制器对显示器的某一些像素点进行刷新从而显示出对应字符。&lt;/p&gt;

&lt;p&gt;：docker里能bind CPU，是真的bind吗？&lt;/p&gt;

&lt;p&gt;是，基于 cgroup&lt;/p&gt;

&lt;p&gt;：死锁怎么产生的？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;互斥&lt;/li&gt;
  &lt;li&gt;请求和保持&lt;/li&gt;
  &lt;li&gt;循环等待&lt;/li&gt;
  &lt;li&gt;不剥夺&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：怎么解决死锁？&lt;/p&gt;

&lt;p&gt;最好不要用锁，或者少用锁，考虑 channel。或者一次性分配资源、可剥夺资源、只要有一个资源得不到分配，也不给这个进程分配其他的资源&lt;/p&gt;

&lt;p&gt;超时放弃 + 确定加锁顺序获取锁&lt;/p&gt;

&lt;p&gt;：如果同时有大量客户并发建立连接，服务器端有什么机制进行处理？&lt;/p&gt;

&lt;p&gt;负载均衡、线程池/进程池处理连接、连接数限制、缓存、I/O多路复用&lt;/p&gt;

&lt;p&gt;：IO密集型 CPU密集型 进来 怎么调整线程池参数？&lt;/p&gt;

&lt;p&gt;IO密集型需要多线程，线程等待时间所占比例越高，需要越多线程 ，启用其他线程继续使用CPU，以此提高CPU的利用率&lt;/p&gt;

&lt;p&gt;CPU密集型不能有太多线程，线程CPU时间所占比例越高，需要越少的线程 。 任务越多，花在进程、线程切换的时间就越多，通常线程数和CPU核数一致即可&lt;/p&gt;

&lt;h3 id=&quot;网络&quot;&gt;网络&lt;/h3&gt;

&lt;p&gt;：TCP和UDP的区别，TCP为什么能保证可靠传输?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TCP可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有&lt;/li&gt;
  &lt;li&gt;TCP 作为一种面向连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费&lt;/li&gt;
  &lt;li&gt;TCP是面向&lt;strong&gt;面向字节流&lt;/strong&gt;，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流&lt;/li&gt;
  &lt;li&gt;根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ &lt;strong&gt;主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制&lt;/strong&gt;等机制实现）&lt;/li&gt;
  &lt;li&gt;UDP 是&lt;strong&gt;面向报文&lt;/strong&gt;的，所谓面向报文，是指面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。应用程序必须选择合适大小的报文，若报文太长，则IP层需要分片，降低效率&lt;/li&gt;
  &lt;li&gt;UDP 是&lt;strong&gt;不可靠&lt;/strong&gt;的，细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达&lt;/li&gt;
  &lt;li&gt;传输途中出现丢包，UDP 也不负责重发&lt;/li&gt;
  &lt;li&gt;它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制&lt;/li&gt;
  &lt;li&gt;即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：TCP和UDP的使用场景？&lt;/p&gt;

&lt;p&gt;TCP：邮箱（SMTP）、远程终端接入（TELNET）、HTTP、FTP&lt;/p&gt;

&lt;p&gt;UDP：DNS、文件传输（TFTP）、网络管理（SNMP）、远程文件服务器（NFS）&lt;/p&gt;

&lt;p&gt;：HTTP长连接怎么保活？&lt;/p&gt;

&lt;p&gt;HTTP是 well-known 的短连接，client 向 server 发送一个 request，得到 response 后，连接就关闭，好处是，可以极大的减轻服务端的压力。&lt;/p&gt;

&lt;p&gt;长连接引入 &lt;strong&gt;keep-alive&lt;/strong&gt;，因为网页除了文本还有 js、css、assets等，有时候还有 async request，如果每次都创建连接然后关闭代价太大。&lt;/p&gt;

&lt;p&gt;所以&lt;strong&gt;连接能够在短时间内得到复用&lt;/strong&gt;就是 keep-alive 的作用，如果开启 keep-alive，则服务端在返回 response 后不关闭 TCP 连接&lt;/p&gt;

&lt;p&gt;HTTP/1.1 协议中，默认开启 keep-alive，除非显式地关闭它：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Connection: close&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果客户端和服务端的确需要进行多次通信，则开启 keep-alive 是更好的选择&lt;/strong&gt;，例如在微服务架构中，通常微服务的使用方和提供方会长期有交流；&lt;strong&gt;在一些 TPS/QPS 很高的 REST 服务中，如果使用的是短连接（即没有开启keep-alive），则很可能发生客户端端口被占满的情形&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;这是由于短时间内会创建大量TCP 连接，而在 TCP 四次挥手结束后，客户端的端口会处于 TIME_WAIT一段时间(2*MSL)，&lt;/p&gt;

    &lt;p&gt;这期间端口不会被释放，从而导致端口被占满。这种情况下最好使用长连接。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：TCP中Close Wait状态服务器还能不能发送数据？&lt;/p&gt;

&lt;p&gt;可以，2*MSL之间可以重发，之后就会关闭连接&lt;/p&gt;

&lt;p&gt;：点一个https请求，前端到后端的交互过程？&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[2.2 键入网址到网页显示，期间发生了什么？&lt;/td&gt;
      &lt;td&gt;小林coding (xiaolincoding.com)](https://xiaolincoding.com/network/1_base/what_happen_url.html#孤单小弟-http)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;：为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/aaron/Library/Application Support/typora-user-images/image-20230721224717750.png&quot; alt=&quot;image-20230721224717750&quot; /&gt;&lt;/p&gt;

&lt;p&gt;答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。&lt;/p&gt;

&lt;p&gt;：&lt;strong&gt;HTTPS 的传输过程是怎样的？&lt;/strong&gt;
客户端发起 HTTPS 请求，服务端返回证书和公钥，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数，通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。&lt;/p&gt;

&lt;p&gt;：HTTPS用的是对称加密还是非对称加密？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;两者都用了&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;使用非对称加密传输一个对称密钥K&lt;/strong&gt;，让服务器和客户端都得知。然后两边都&lt;strong&gt;使用这个对称密钥K来加密解密收发数据&lt;/strong&gt;。因为&lt;strong&gt;传输密钥K是用非对称加密方式&lt;/strong&gt;，很难破解比较安全。而&lt;strong&gt;具体传输数据则是用对称加密方式&lt;/strong&gt;，加快传输速度。两全其美&lt;/p&gt;

&lt;p&gt;：RPC的优势？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;抽象屏蔽：RPC框架可以屏蔽底层的网络通信细节，使得远程调用就像本地调用一样简单。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可扩展性：RPC框架可以支持多种协议和编码方式，可以适应不同场景的需求，同时也可以方便地添加新的功能和服务。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可靠性：RPC框架通常会提供各种机制来保证通信的可靠性，如超时重试、错误处理等。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;高效性：RPC框架通常使用&lt;strong&gt;二进制协议和高效的序列化&lt;/strong&gt;方式，可以大大减少网络传输的数据量，提高系统的性能。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;语言无关性：RPC框架可以支持多种编程语言，使得不同语言的程序可以方便地进行交互和通讯。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：OAuth2.0了解吗？&lt;/p&gt;

&lt;p&gt;一个业界标准的授权协议，授权码模式被广泛应用于第三方互联网开放平台，通过第三方登录是其最常见应用场景之一。&lt;/p&gt;

&lt;p&gt;可以这样理解，OAuth 2.0提供一种协议交互框架，让某个应用能够以安全地方式获取到用户的委派书，这个委派书在OAuth 2.0中就是访问令牌（access token），随后应用便可以使用该委派书，代表用户来访问用户的相关资源&lt;/p&gt;

&lt;p&gt;：Nginx了解吗说一说？&lt;/p&gt;

&lt;p&gt;Nginx的一些特性：跨平台、非阻塞、高并发、接受用户请求异步&lt;/p&gt;

&lt;p&gt;：使用“反向代理服务器”的优点是什么?&lt;/p&gt;

&lt;p&gt;反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当使用web托管服务时。&lt;/p&gt;

&lt;p&gt;：Http Code，你知道 3XX 状态码 对应的是什么？&lt;/p&gt;

&lt;p&gt;1XX：临时的响应&lt;/p&gt;

&lt;p&gt;2XX：服务器成功的接收了客户端请求&lt;/p&gt;

&lt;p&gt;3XX：客户端浏览器必须采取更多操作来实现请求&lt;/p&gt;

&lt;p&gt;4XX类：发生错误，客户端似乎有问题&lt;/p&gt;

&lt;p&gt;5XX类：服务器遇到错误而不能完成该请求&lt;/p&gt;

&lt;p&gt;：osi网络七层模型？&lt;/p&gt;

&lt;p&gt;自下而上：物理层（bit）、数据链路层（帧）、网络层（报文）、传输层、会话层、表示层、应用层&lt;/p&gt;

&lt;p&gt;：http/2.0 和 http/1.1 区别？&lt;/p&gt;

&lt;p&gt;http2.0采用了多路复用，而且不用顺序一一对应。还做了header压缩和服务端推送（推送热点到缓存）&lt;/p&gt;

&lt;p&gt;：TCP为什么四次挥手？&lt;/p&gt;

&lt;p&gt;本质的原因是tcp是全双工的，要实现可靠的连接关闭，A发出结束报文FIN，收到B确认后A知道自己没有数据需要发送了，B知道A不再发送数据了，自己也不会接收数据了，但是此时A还是可以接收数据，B也可以发送数据；当B发出FIN报文的时候此时两边才会真正的断开连接，读写分开&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;关闭连接时，客户端向服务端发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FIN&lt;/code&gt; 时，仅仅表示客户端不再发送数据了但是还能接收数据。&lt;/li&gt;
  &lt;li&gt;服务器收到客户端的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FIN&lt;/code&gt; 报文时，先回一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ACK&lt;/code&gt;，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FIN&lt;/code&gt; 报文给客户端来表示同意现在关闭连接。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;go&quot;&gt;Go&lt;/h3&gt;

&lt;p&gt;：go 怎么性能分析？&lt;/p&gt;

&lt;p&gt;go tool pprof 和 go-torch 火焰图&lt;/p&gt;

&lt;p&gt;：谈谈垃圾收集原理？以及垃圾收集算法？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;标记清除算法：&lt;/strong&gt;算法分为标记和清除两个阶段，首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象；
    &lt;ul&gt;
      &lt;li&gt;缺点在于，&lt;strong&gt;垃圾被回收以后造成了大量不连续的内存碎片&lt;/strong&gt;。碎片太多可能会导致以后需要分配较大对象时，无法找到连续的足够内存从而频繁触发垃圾收集，降低系统效率。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;复制算法&lt;/strong&gt;：为了解决“标记清除”算法的问题，它将内存平均分为两块，每次只使用其中一块，&lt;strong&gt;当这一块存满时触发垃圾收集，将还存活的对象复制到另一块内存&lt;/strong&gt;，然后将这块内存清掉，这样就不会存在内存碎片的问题。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;标记整理算法&lt;/strong&gt;：复制算法在存活对象较多的时候需要复制的操作也较多，最关键的是只能利用一半的内存，标记整理算法中的标记和标记清除算法一样，&lt;strong&gt;要被回收的对象找出来以后让所有存活的对象向一端移动（俄罗斯方块），然后将内存的剩余部分直接清理掉&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分代收集算法&lt;/strong&gt;：分代收集算法将内存分为&lt;strong&gt;新生代（标记复制）和老年代（标记整理）&lt;/strong&gt;，新生代又分为：较大的Eden区（占80%）和两块Survivor区(各占10%)，&lt;strong&gt;刚刚创建的对象存放在新生代的Eden区。&lt;/strong&gt;因为绝大多数的对象（98%）都是朝生夕死的，当Eden区没有足够的空间的时候虚拟机会发起一次Minor Gc，Minor Gc之后，存活对象会进入其中的一块Suvivor区，Eden区被清空，如果Suvivor区内存不够则直接进入老年代。下一次Minor Gc会将Eden和该Suvivor区的存活对象复制到另一块Suvivor区，并将Eden区和该Suvivor区清空。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;大对象会直接进入老年代&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;长期存活的对象会进入老年代&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;：为什么不在新生代使用标记整理算法？或者在老年代使用复制算法？&lt;/p&gt;

&lt;p&gt;老年代对象大，复制成本高；新生代对象小，gc次数多，频繁整理内存代价高&lt;/p&gt;

&lt;p&gt;：go recover怎用？&lt;/p&gt;

&lt;p&gt;defer里&lt;/p&gt;

&lt;p&gt;：逃逸分析？&lt;/p&gt;

&lt;p&gt;相比于把内存分配到堆中，分配到栈中优势更明显，go也是这么做的。但是编译器无法证明函数返回的变量有没有被引用时，就必须分配在堆上以避免dangling pointer，另外如果局部变量很大，也会分配在对堆上。具体的位置就需要逃逸分析来确定。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则在栈上分配。否则，就是所谓的逃逸，必须在堆上进行分配。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go build -gcflags &apos;-m -m -l&apos;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;mysql&quot;&gt;MySQL&lt;/h3&gt;

&lt;p&gt;：MySQL的隔离级别有哪几种？&lt;/p&gt;

&lt;p&gt;四种。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Read Uncomitted：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。读取未提交的数据，也被称之为脏读。&lt;/li&gt;
  &lt;li&gt;Read Committed：这是大多数数据库系统的默认隔离级别（但&lt;strong&gt;不是&lt;/strong&gt;MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。
    &lt;ul&gt;
      &lt;li&gt;这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一select可能返回不同结果。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeatable Read&lt;/strong&gt;：默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;幻读：指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行&lt;/li&gt;
  &lt;li&gt;InnoDB和Falcon存储引擎通过MVCC机制解决了该问题&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Serializable&lt;/strong&gt;：这是最高的隔离级别，强制事务排序，使之&lt;strong&gt;不可能相互冲突&lt;/strong&gt;从而解决幻读问题。简言之，它是在每个读的数据&lt;strong&gt;行上加上共享锁&lt;/strong&gt;。在这个级别，可能&lt;strong&gt;导致大量的超时现象和锁竞争&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。&lt;/li&gt;
  &lt;li&gt;不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。&lt;/li&gt;
  &lt;li&gt;幻读(Phantom Read):在一个事务的两次查询中数据数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就有几列数据是未查询出来的，如果此时插入了另外一个事务插入的数据，就会报错。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：脏读和幻读分别是什么？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;脏读&lt;/strong&gt;：一个事务在处理过程中读取了另外一个事务未提交的数据。&lt;/p&gt;

&lt;p&gt;你都还没提交，我就读到了你刚操作的数据，万一你回滚了怎么办，你说这脏不脏。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;幻读&lt;/strong&gt;：在一个事务A中，第一次查询某条记录，是没有的，但是，当试图更新这条不存在的记录时，竟然能成功，并且，再次读取同一条记录，它就神奇地出现了。（B在中间commit了）&lt;/p&gt;

&lt;p&gt;实际上，在InnoDB引擎中，对于索引的扫描，不仅锁住扫描到的索引，而且还锁住这些索引覆盖的范围（gap），因此这个范围是内插入数据是不允许的。&lt;/p&gt;

&lt;p&gt;：B Tree 和 B+ Tree的区别？&lt;/p&gt;

&lt;p&gt;在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度；B树每个节点都有data&lt;/p&gt;

&lt;p&gt;：MySQL中如果使用like进行模糊匹配的时候，是否会使用索引？一定不会用么？&lt;/p&gt;

&lt;p&gt;如果前缀是 % 索引不知道怎么匹配就不会用。不走索引的优化：LOCATE&lt;/p&gt;

&lt;p&gt;：MVCC介绍一下？&lt;/p&gt;

&lt;p&gt;事务每次开启前，都会从数据库获得一个&lt;strong&gt;自增&lt;/strong&gt;的事务ID，可以从事务ID判断事务的执行先后顺序。这就是事务版本号。&lt;/p&gt;

&lt;p&gt;让读写之间也不冲突的方法，就是读取数据时通过一种类似快照的方式将数据保存下来，这样读锁就和写锁不冲突了，不同的事务session会看到自己特定版本的数据&lt;/p&gt;

&lt;p&gt;InnoDB中通过undo log实现了数据的多版本（undo log除了实现MVCC外，还用于事务的回滚），而并发控制通过锁来实现。&lt;/p&gt;

&lt;p&gt;：mysql中有哪些锁？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;按锁粒度分类&lt;/strong&gt;：&lt;strong&gt;行级锁&amp;amp;表级锁&amp;amp;页级锁&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;行级锁：开销大，加锁慢；会出现&lt;strong&gt;死锁&lt;/strong&gt;；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。&lt;/li&gt;
  &lt;li&gt;表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。&lt;/li&gt;
  &lt;li&gt;页面锁：开销和加锁时间界于表锁和行锁之间；会出现&lt;strong&gt;死锁&lt;/strong&gt;；锁定粒度界于表锁和行锁之间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;锁级别分类&lt;/strong&gt;：&lt;strong&gt;共享锁 &amp;amp; 排他锁 &amp;amp; 意向锁&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;共享锁（Share Lock），可以并发读取数据，但任何事务都不能对数据进行修改。
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT ... LOCK IN SHARE MODE;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;排他锁（Exclusive Lock）
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT ... FOR UPDATE;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;意向锁（Intention Lock），表级锁，主要是为了在一个事务中揭示下一行将要被请求锁的类型，InnoDB自动加的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：mysql如果要记录货币，用什么类型？&lt;/p&gt;

&lt;p&gt;肯定不能用浮点数，有误差。用 DECIMAL或者 NUMERIC，他们的值是字符串存储。&lt;/p&gt;

&lt;p&gt;：存 IP 地址用什么类型？&lt;/p&gt;

&lt;p&gt;32 位无符号整数。对于转换来说，MySQL提供了相应的函数来把字符串格式的IP转换成整数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INET_ATON&lt;/code&gt;，以及把整数格式的IP转换成字符串的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INET_NTOA&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;省空间，不管是数据存储空间，还是索引存储空间&lt;/li&gt;
  &lt;li&gt;便于使用范围查询（BETWEEN…AND），且效率更高&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;redis&quot;&gt;Redis&lt;/h3&gt;

&lt;p&gt;：用redis实现排行榜？&lt;/p&gt;

&lt;p&gt;用 ZSET。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZADD key score value&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZINCRBY key increment member&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZRANGE key start stop [WITHSCORES]&lt;/code&gt;，按照 score 递增顺序返回 start 到 stop&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZREVRANGE key start stop [WITHSCORES]&lt;/code&gt;，按照 score 递减顺序返回 start 到 stop&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZRANK key member&lt;/code&gt;，在 key 里查 member 的排行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：如果排行榜中包含100万用户，每个用户对应一个分数，区间0-100，每个用户想查到自己的排名，可以如何优化？（不能修改原数据）&lt;/p&gt;

&lt;p&gt;统计出每个score用户数量，然后对score进行合理范围拆分。现在是[0, 100]，那就拆分成[0, 10], [10, 20]，[20, 30]，这样每个桶就是 10w 人。&lt;/p&gt;

&lt;p&gt;对于查询 TOP 排名时，只要查看最高分区桶 **sorted set **排名即可&lt;/p&gt;

&lt;p&gt;对于查询个体用户的排名，需要外加一份用户得分记录存储于MySQL等数据库中，用于查询到单用户的得分，然后依据得分查找到得分存储在相应redis sorted set分桶排名，然后把高于当前分桶范围的分桶用户相加得到相关用户的排名。&lt;/p&gt;

&lt;p&gt;：如果不用redis怎么做排行榜？&lt;/p&gt;

&lt;p&gt;当用户量级很大时，首先要 &lt;strong&gt;分库分表&lt;/strong&gt; ，通常是水平分表，根据一定规则（比如 id）把用户数据行分批存储在多个数据表中。然后用 MapReduce，不够就加机器水平扩容。&lt;/p&gt;

&lt;p&gt;：Redis，它会存在线程切换的问题么？&lt;/p&gt;

&lt;p&gt;redis是单线程的，redis 6.0之后处理网络请求是多线程，但是执行指令还是单线程&lt;/p&gt;

&lt;p&gt;：Redis的大Key的问题？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;所谓的大key问题是某个key的value比较大，所以本质上是大value问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最典型的就是阻塞线程，并发量下降，导致客户端超时，服务端业务成功率下降&lt;/strong&gt;。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;删除大 key &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNLINK 命令不同与 DEL 命令在于它是异步执行的，因此它不会阻塞&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;压缩和拆分key
    &lt;ul&gt;
      &lt;li&gt;当vaule是string时，比较难拆分，则使用序列化、压缩算法将key的大小控制在合理范围内，但是序列化和反序列化都会带来更多时间上的消耗&lt;/li&gt;
      &lt;li&gt;当value是string，压缩之后仍然是大key，则需要进行&lt;strong&gt;拆分&lt;/strong&gt;，一个大key分为不同的部分，记录每个部分的key，使用&lt;strong&gt;multiget&lt;/strong&gt;等操作实现事务读取&lt;/li&gt;
      &lt;li&gt;当value是list/set等集合类型时，根据预估的数据规模来进行&lt;strong&gt;分片&lt;/strong&gt;，不同的元素计算后分到不同的片&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;：Redis中大面积的缓存失效，然后请求全部打到数据库，有什么解决方法？&lt;/p&gt;

&lt;p&gt;TTL 加随机数&lt;/p&gt;

&lt;p&gt;：如果出现一些热点数据，比如明星之间的新闻，造成大量的吃瓜用户涌入后台，但是服务器还没有缓存对应的数据，这样可能造成数据库宕机，如何避免这样的情况？&lt;/p&gt;

&lt;p&gt;提前缓存热点数据、限流、对单一key限流、熔断降级返回一个固定值、热点数据隔离、mq&lt;/p&gt;

&lt;p&gt;：redis持久化的方式？&lt;/p&gt;

&lt;p&gt;RDB（Redis Database）、AOF（Append-Only File）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AOF会记录过程，RDB只管结果&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RDB保存的是某一时刻的快照（通过一些事件触发快照，例如主从复制）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主进程fork子进程，可以最大化Redis性能（fork的时候是阻塞的）&lt;/li&gt;
  &lt;li&gt;子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行&lt;strong&gt;原子替换&lt;/strong&gt;（RDB始终完整）&lt;/li&gt;
  &lt;li&gt;子进程发送信号给父进程表示完成，父进程更新统计信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AOF对数据库进行过&lt;strong&gt;写入的命令（及其参数）记录到 AOF 文件&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;应用场合：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;内存数据库 rdb+aof 数据不容易丢&lt;/li&gt;
  &lt;li&gt;缓存服务器 rdb 性能高&lt;/li&gt;
  &lt;li&gt;不建议 只使用 aof (性能差)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：redis和db的数据一致性有什么方法保证？&lt;/p&gt;

&lt;h3 id=&quot;linux&quot;&gt;Linux&lt;/h3&gt;

&lt;p&gt;：linux 如何查看网络带宽？&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# 网络带宽&lt;/span&gt;
ethtool 网卡名称
nload 网卡名称
dstat &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 端口占用&lt;/span&gt;
lsof &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt;:[port]
netstat &lt;span class=&quot;nt&quot;&gt;-tunlp&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;port]

&lt;span class=&quot;c&quot;&gt;# 网络占用 sar(System Activity Reporter)&lt;/span&gt;
sar &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; DEV &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;interval] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;count]
sar &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; DEV 1 5 &lt;span class=&quot;c&quot;&gt;# 每1秒统计一次网络接口的活动状况，连续统计5次&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;：Linux怎么查看当前的负载情况？&lt;/p&gt;

&lt;p&gt;top、vmstat&lt;/p&gt;

&lt;p&gt;cat /proc/cpuinfo ：即可查看CPU信息&lt;/p&gt;

&lt;p&gt;sar：可以监控系统所有资源状态，sar -n DEV查网卡流量历史、sar -q 查看历史负载，最有用的就是查网卡流量，流量过大：rxpck/s大于4000,或者rxKB/s大于5000，则很有可能被攻击了&lt;/p&gt;

&lt;p&gt;ps：查看进程&lt;/p&gt;

&lt;p&gt;netstat：查看端口&lt;/p&gt;

&lt;p&gt;：linux中的vi与vim的区别有哪些？&lt;/p&gt;

&lt;p&gt;vim 是vi的升级版本，它不仅兼容vi的所有指令，而且还有一些新的特性&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;多级撤消&lt;/li&gt;
  &lt;li&gt;语法高亮&lt;/li&gt;
  &lt;li&gt;visual mode&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;：tail和cat的区别？&lt;/p&gt;

&lt;p&gt;cat查看全部数据，是静态的。tail可以查看文档更新情况 是动态的&lt;/p&gt;

&lt;p&gt;：如果Linux下需要打开或者查看大文件，你会怎么做？&lt;/p&gt;

&lt;p&gt;分割&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head -10000 xxx.log &amp;gt; tmp.log&lt;/code&gt; 查看前10000行&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tail -10000 xxx.log &amp;gt; tmp.log&lt;/code&gt; 查看后10000行&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed -n &apos;10,10000p&apos; xxx.log &amp;gt; tmp.log&lt;/code&gt; 查看10～10000行&lt;/p&gt;

&lt;p&gt;：什么是僵尸进程和孤儿进程？&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;当一个子进程结束运行（一般是调用exit、运行时发生致命错误或收到终止信号所导致）时，子进程的退出状态（返回值）会回报给操作系统，系统则以SIGCHLD信号将子进程被结束的事件告知父进程，此时子进程的进程控制块（PCB）仍驻留在内存中。一般来说，收到SIGCHLD后，父进程会使用wait系统调用以获取子进程的退出状态，然后内核就可以从内存中释放已结束的子进程的PCB；而如若父进程没有这么做的话，子进程的PCB就会一直驻留在内存中，也即成为僵尸进程&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;僵尸进程：&lt;/strong&gt;当进程退出但是父进程并没有调用wait或waitpid获取子进程的状态信息时就会产生僵尸进程&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;孤儿进程：&lt;/strong&gt;当一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作&lt;/p&gt;

&lt;p&gt;：怎么查看僵尸进程和孤儿进程？&lt;/p&gt;

&lt;p&gt;僵尸：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -A -o stat,ppid,pid,cmd | grpe -e &apos;^[Zz]&apos;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;孤儿：PID为1的进程&lt;/p&gt;

&lt;h3 id=&quot;服务治理&quot;&gt;服务治理&lt;/h3&gt;

&lt;p&gt;：如何看服务的瓶颈？&lt;/p&gt;

&lt;p&gt;借助于现有的开源平台和工具做监控&lt;/p&gt;

&lt;p&gt;OS层面：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU：CPU的上下文切换情况可通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vmstat&lt;/code&gt; 命令可以查看&lt;/li&gt;
  &lt;li&gt;Memory：free –m 命令查看内存的使用，top 命令可以查看进程使用的虚拟内存 VIRT 和物理内存 RES&lt;/li&gt;
  &lt;li&gt;IO：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iostat&lt;/code&gt; 可以查看磁盘的读写情况，通过 CPU 的 I/O wait 可以看出磁盘 I/O 是否正常。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GO层面：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;profiling：cpu profiling、heap profiling&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;tracing&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go tool pprof http://localhost:6060/debug/pprof/trace?seconds=20 &amp;gt; trace.out&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go tool trace trace.out&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GC：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GODEBUG=gctrace=1 go run main.go   &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：如何保障日志在宕机时不丢失？&lt;/p&gt;

&lt;p&gt;任何写文件，都没办法在操作系统/虚拟机/物理器突然宕机时保证完全不丢。&lt;/p&gt;

&lt;p&gt;因为程序里IO写入文件，实际只写到了操作系统的&lt;strong&gt;buffer&lt;/strong&gt;里，由&lt;strong&gt;操作系统负责真正写&lt;/strong&gt;到磁盘。&lt;/p&gt;

&lt;p&gt;所以，操作系统层面突然crash，buffer丢了，大家都玩完。而只要数据写入操作系统buffer，那么写数据的这个进程自己宕掉了，其实无所谓的，操作系统一定能完成任务，当然前提是：磁盘没有出问题。&lt;/p&gt;

&lt;p&gt;一般情况下为了日志性能，不会直接flush磁盘的，而是用了buffered按容量大小或条数来刷，或者加了async、使用异步方式写日志文件，此时进程崩溃或者服务器宕机会丢日志。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;对于同步方式，可以每次都flush来保证日志数据发送到了操作系统，只要操作系统/服务器不突然宕机，服务器就会保证日志写入磁盘，就可以不丢，但是这样性能会非常低。对于异步方式，不管是进程突然崩溃、还是服务器宕机都无解。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于磁盘没有空间了，磁盘坏了，日志采集工具跟不上，这些一般来说也是无解的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;虽然可以用其他的appender（非fileAppender），比如jms/kafka等把日志写到其他存储方式，但是没用，还是会优先走内部的同步异步/buffered机制。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;如果完全不考虑性能，可以自定义一个mq或db的appender，利用事务机制，成功写入MQ或数据库再返回，可以保证日志一条都不丢。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;：微服务是个什么样的理念？&lt;/p&gt;

&lt;p&gt;字面上来看，微服务可以这样子理解：“微”：小型，不大，“服务”：一个个单独运行的进程，合起来就是一个个小型，可以单独运行的进程&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;官方解释：&lt;/strong&gt;微服务是一种架构风格，一种架构模式，它提倡将单一的应用程序划分为一个个小的服务，每个服务都是单独存在，单独运行。通过服务之间的互相协调，互相配置，可以达到单一的应用程序所产生的效果，为用户提供最终的价值。服务之间采用轻量级的通信机制（如：RPG，http等）互相沟通，每个服务围绕具体的业务进行构建，并且可以单独部署到生产环境中去，通过使用一些轻量级的集中式管理工具来对服务进行统一的协调和管理，每个微服务可以由不同的编程语言来编写，建议每个服务都有自己的数据库。&lt;/p&gt;

&lt;p&gt;：说说链路追踪？&lt;/p&gt;

&lt;p&gt;对于一些规模较大的分布式系统，一个用户的请求，可能需要涉及到多个子系统的流转。而且随着业务的不断增长，服务之间的调用关系也会越来越复杂。在这样一个背景下，我们需要去了解整个请求链路的调用关系，去定位到性能问题，另一方面还需要从整体到局部展示各项系统指标，快速实现故障定位和恢复。所以产生了链路追踪的需求&lt;/p&gt;

&lt;p&gt;：链路追踪是如何实现的？&lt;/p&gt;

&lt;p&gt;比如open tracing协议的数据模型：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trace：一个完整请求链路&lt;/li&gt;
  &lt;li&gt;Span：一次调用过程&lt;/li&gt;
  &lt;li&gt;SpanContext：Trace的全局上下文，里面有traceId&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一次下单的完整请求就是一个 Trace。TraceId是这个请求的全局标识。内部的每一次调用就称为一个 Span，每个 Span 都要带上全局的 TraceId，这样才可把全局 TraceId 与每个调用关联起来。这个 TraceId 是通过 SpanContext 传输的，既然要传输，显然都要遵循协议来调用。如果我们把传输协议比作车，把 SpanContext 比作货，把 Span 比作路应该会更好理解一些&lt;/p&gt;

&lt;p&gt;底层有一个 collector 一直在收集数据：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;全局 trace_id、span_id、parent_span_id&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：说说Promethues？&lt;/p&gt;

&lt;p&gt;Prometheus的基本原理是通过HTTP周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口并符合Prometheus定义的数据格式，就可以介入Prometheus监控。&lt;/p&gt;

&lt;p&gt;Prometheus 存储的所有数据都是&lt;strong&gt;时间序列数据&lt;/strong&gt;（&lt;strong&gt;Time Serie Data&lt;/strong&gt;）。时序数据是具有时间戳的数据流，该数据流属于某个 metric 和该 metric 下的多个 label。&lt;/p&gt;

&lt;h3 id=&quot;中间件&quot;&gt;中间件&lt;/h3&gt;

&lt;p&gt;：RabbitMQ和其它消息队列的区别？例如Kafka、RocketMQ&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kafka：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;号称大数据的杀手锏，百万级TPS的&lt;strong&gt;吞吐量&lt;/strong&gt;，超高的&lt;strong&gt;可用性&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;在实时计算以及日志采集被大规模使用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;RabbitMQ：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;erlang 特性，性能好，高并发&lt;/li&gt;
  &lt;li&gt;吞吐不错，管理界面非常棒很好用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;RocketMQ：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;消息可靠性：经过参数优化配置，消息可以做到0丢失&lt;/li&gt;
  &lt;li&gt;支持10亿级别的消息堆积，不会因为堆积导致性能下降&lt;/li&gt;
  &lt;li&gt;稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;：如果用户量很大，rabbitMQ扛不住怎么办？要求不只是在硬件方面&lt;/p&gt;

&lt;p&gt;直接换高吞吐的 kafka 或者 rocketMQ；&lt;/p&gt;

&lt;p&gt;考虑集群镜像&lt;/p&gt;

&lt;p&gt;：mq的使用场景？为什么使用？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;异步解藕：正常业务流程中，比较耗时而且不需要即时返回结果的操作&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;流量削峰填谷：&lt;/strong&gt;一般在秒杀、搞活动中使用广泛。将需要处理的消息全部放入其中，系统按照最大处理能力，去获取消息进行消费&lt;/li&gt;
  &lt;li&gt;分布式事务的数据一致性：目前主流的MQ框架，都支持分布式事务消息&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;一些实际问题&quot;&gt;一些实际问题&lt;/h3&gt;

&lt;p&gt;：用户密码怎么存？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BAD：&lt;/strong&gt;MD5、SHA1等单向 HASH 算法不行，因为现在有彩虹表。在单向HASH基础上加salt也不行，因为泄露了也可以重建彩虹表。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GOOD&lt;/strong&gt;：PBKDF2算法，原理跟加盐差不多。HASH 选 sha1/sha256，salt 长度不能少于 8 字节，HASH至少1000次。一次密码验证过程进行1000次HASH运算，对服务器来说可能只需要1ms，但对于破解者来说计算成本增加了1000倍，而至少8字节随机盐，更是把建表难度提升了N个数量级。&lt;/p&gt;

&lt;p&gt;：粉丝表场景，短时间大量关注？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;高并发写。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先考虑限流。&lt;/p&gt;

&lt;p&gt;没缓存的情况下，mq削峰，后台启动若干个队列处理程序，消费消息队列中的消息&lt;/p&gt;

&lt;p&gt;可以考虑批量提交、MyISAM&lt;/p&gt;

&lt;p&gt;因为InnoDB的锁级别为行锁并且是事务性的，而MyisAM为表锁且无事务，因此MyisAM引擎对于频繁数据更新和插入的效率远大于InnoDB引擎&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Jul 2023 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2023/07/24/interview/</link>
        <guid isPermaLink="true">http://localhost:4000/2023/07/24/interview/</guid>
        
        <category>interview</category>
        
        <category>golang</category>
        
        <category>计算机网络</category>
        
        <category>操作系统</category>
        
        
      </item>
    
  </channel>
</rss>
